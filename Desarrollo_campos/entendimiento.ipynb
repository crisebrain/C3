{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalar nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr aquí\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import print_function\n",
    "import spaghetti as sgt\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descargar los corpus\n",
    "```python \n",
    "nltk.download()\n",
    "```\n",
    "\n",
    "### archivos contenidos en carpeta\n",
    "- spaghetti.py\n",
    "- facturaskeys.json\n",
    "- entendimiento.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definicion de palabras asociadas a los campos y de patrones de expresiones regulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Prefijo': ['prefijo', 'serie'], 'NoDocumento': ['documento', 'documentos', 'nota', 'notas', 'credito', 'creditos', 'facturas', 'factura', 'numero']}\n"
     ]
    }
   ],
   "source": [
    "dictfacturas = json.load(open(\"facturaskeys.json\"))\n",
    "print(dictfacturas)\n",
    "\n",
    "patterns = dict(Cuenta=r\"\\b[A-Za-z]{3}\\d{3}\\b\",\n",
    "                Prefijo=r\"\\b[1-9a-zA-Z]\\w{0,3}\\b\",  # wvect\n",
    "                NoDocumento=r\"\\b[0-9a-zA-Z\\-]{1,40}\\b\",  # w2vect\n",
    "                NitAdquirienteMex=r\"\\b[A-Za-z]{4}\\d{6}[A-Za-z0-9]{3}\\b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA: \n",
    "\n",
    "    Añadir al archivo facturaskeys.json los sinónimos que crean necesarios para cada campo, \n",
    "    respetando la estructura json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regexextractor(expression, field):\n",
    "    pattern = patterns[field]\n",
    "    result = re.search(pattern=pattern, string=expression)\n",
    "    if result:\n",
    "        return result.group()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def do_tagging(exp, field):\n",
    "    tokens = nltk.word_tokenize(exp)\n",
    "    tagged = sgt.pos_tag(tokens)\n",
    "    tagged = np.array([list(tup) for tup in tagged]).astype(str)\n",
    "    mask = tagged[:, 1] == 'None'\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in dictfacturas[field]:\n",
    "            tagged[i, 1] = str(field)\n",
    "    unknowns, = np.where(mask)\n",
    "    for unknown in unknowns:\n",
    "        if tagged[unknown, 0] in dictfacturas[field]:\n",
    "            tagged[unknown, 1] = field\n",
    "        else:\n",
    "            if regexextractor(tokens[unknown], field) is not None:\n",
    "                tagged[unknown, 1] = \"dato\"\n",
    "            else:\n",
    "                tagged[unknown, 1] = \"unknown\"\n",
    "    return [tuple(wordtagged) for wordtagged in tagged]\n",
    "\n",
    "def do_chunking(grammar, tagged, field, code):\n",
    "    cp = nltk.RegexpParser(grammar)\n",
    "    chunked = cp.parse(tagged)\n",
    "    # añadir las condiciones que sean necesarias para contemplar\n",
    "    # los posibles valores\n",
    "    posibles = [\"dato\", \"Z\", \"ncfs000\", \"ncms000\", \"Fz\",\n",
    "                \"sps00\"]\n",
    "    # posibles son los tipos de palabras que pueden representar al dato\n",
    "    continuous_chunk = []\n",
    "    entity = []\n",
    "    unknowns = []\n",
    "    subt = []\n",
    "    for i, subtree in enumerate(chunked):\n",
    "        if isinstance(subtree, nltk.Tree) and subtree.label() == \"NP\":\n",
    "            # añadir las condiciones que sean necesarias para contemplar los posibles valores\n",
    "            entity += [token for token, pos in subtree.leaves()\n",
    "                       if pos in posibles]\n",
    "            unknowns += [token for token, pos in subtree.leaves()\n",
    "                         if pos == \"unknown\"]\n",
    "            subt.append(subtree)\n",
    "    if entity == []:\n",
    "        code = 0\n",
    "        if len(unknowns) > 1:\n",
    "            entity = unknowns[-1].upper()\n",
    "        elif unknowns != []:\n",
    "            entity = unknowns[0].upper()\n",
    "        else:\n",
    "            entity = None\n",
    "    elif len(entity) > 1:\n",
    "        code = 0\n",
    "        entity = entity[-1].upper()\n",
    "    else:\n",
    "        entity = entity[0].upper()\n",
    "        if regexextractor(entity, field) is not None:\n",
    "            code = 1\n",
    "        else:\n",
    "            code = 0\n",
    "    return entity, code, subt, tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('las', 'da0fp0'),\n",
       " ('documento', 'NoDocumen'),\n",
       " ('prefijo', 'dato'),\n",
       " ('son', 'vsip3p0'),\n",
       " ('casa', 'ncfs000')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_tagging('las documento prefijo son casa', 'NoDocumento')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA: \n",
    "      \n",
    "      la palabra prefijo no está en el diccionario, por lo tanto como es detectada como desconocida \n",
    "      pero cumple con la expresión regular del campo, la asigna como posible dato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo de grammar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "grammar = r\"\"\"Q: {<dato|Z|Fz|unknown|ncfs000>}\n",
    "              T: {<dato|Fz|unknown|sps00>}\n",
    "              NP: {<Prefijo> <(vs\\w+)|(nc\\w+)|(wmi\\w+)|(spc\\w+)>* <Q>}\n",
    "              NP: {<Prefijo> <T>}\n",
    "              NP: {<Prefijo> <(vmi\\w+)|(aq\\w+)|unknown>? <sp\\w+>? <Q>}\n",
    "              NP: {<Prefijo> <dd0fs0> <vmp00sm> <sps00> <Q>}\n",
    "              NP: {<Q> <(vs\\w+)> <(da\\w+)> <Prefijo>}\n",
    "              NP: {<Q> <(p030\\w+)>? <vmip3s0>? <cs> <Prefijo>}\n",
    "            \"\"\"\n",
    "```\n",
    "### Nota:\n",
    "    \n",
    "    falta definir nodos terminales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para diseñar las reglas y probar\n",
    "\n",
    "NOTA:\n",
    "    \n",
    "    Correr cada que se cambie el grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar = r\"\"\"Q: {<dato|Z|Fz|unknown|ncfs000>}\n",
    "              T: {<dato|Fz|unknown|sps00>}\n",
    "              NP: {<Prefijo> <(vs\\w+)|(nc\\w+)|(wmi\\w+)|(spc\\w+)>* <Q>}\n",
    "              NP: {<Prefijo> <T>}\n",
    "              NP: {<Prefijo> <(vmi\\w+)|(aq\\w+)|unknown>? <sp\\w+>? <Q>}\n",
    "              NP: {<Prefijo> <dd0fs0> <vmp00sm> <sps00> <Q>}\n",
    "              NP: {<Q> <(vs\\w+)> <(da\\w+)> <Prefijo>}\n",
    "              NP: {<Q> <(p030\\w+)>? <vmip3s0>? <cs> <Prefijo>}\n",
    "            \"\"\"\n",
    "\n",
    "def prueba(exp, field): \n",
    "    tagged = do_tagging(exp.lower(), field)\n",
    "    return do_chunking(grammar, tagged, field, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTA:\n",
    "    \n",
    "    salida: (VALOR, CODIGO DE VALIDEZ, FRASE ETIQUETADA QUE CUMPLE CON GRAMMAR, FRASE ETIQUETADA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ESCUELA',\n",
       " 0,\n",
       " [Tree('NP', [Tree('Q', [('escuela', 'ncfs000')]), ('es', 'vsip3s0'), ('el', 'da0ms0'), ('prefijo', 'Prefijo')])],\n",
       " [('escuela', 'ncfs000'),\n",
       "  ('es', 'vsip3s0'),\n",
       "  ('el', 'da0ms0'),\n",
       "  ('prefijo', 'Prefijo')])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp = 'escuela es el prefijo'\n",
    "field = \"Prefijo\"\n",
    "prueba(exp, field)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De Gerardo\n",
    "\n",
    "Valores para agregar en facturaskeys.json\n",
    "\n",
    "```json\n",
    "{\"Estatus\": [\"estado\",\"estatus\"],\n",
    " \"Acuse\": [\"acuse\"]}\n",
    "```\n",
    "Actualizar grammar\n",
    "\n",
    "```python\n",
    "\n",
    "grammar = r\"\"\"NP: {<Estatus> <(vs\\w+)|(nc\\w+)|(wmi\\w+)|(spc\\w+)>* <dato|Z|unknown>}\n",
    "              NP: {<Estatus> <(vmi\\w+)|(aq\\w+)|unknown>? <sp\\w+>? <dato|Z|unknown>}\n",
    "              NP: {<Estatus> <dd0fs0> <vmp00sm> <sps00> <aq0cs0> <ncms000> <pr0ms000> <aq0msp> <vmip3s0> <dato|Z|unknown>}\n",
    "              NP: {<dato|Z|unknown> <(vs\\w+)> <(da\\w+)> <Estatus>}\n",
    "              NP: {<dato|Z|unknown> <(p030\\w+)>? <vmip3s0>? <cs> <Estatus>}\n",
    "           \"\"\"\n",
    "\n",
    "grammar = r\"\"\"NP: {<Acuse> <(vs\\w+)|(nc\\w+)|(wmi\\w+)|(spc\\w+)>* <dato|Z|unknown>}\n",
    "              NP: {<Acuse> <(vmi\\w+)|(aq\\w+)|unknown>? <sp\\w+>? <dato|Z|unknown>}\n",
    "              NP: {<Acuse> <dd0fs0> <vmp00sm> <sps00> <aq0cs0> <ncms000> <pr0ms000> <aq0msp> <vmip3s0> <dato|Z|unknown>}\n",
    "              NP: {<dato|Z|unknown> <(vs\\w+)> <(da\\w+)> <Acuse>}\n",
    "              NP: {<dato|Z|unknown> <(p030\\w+)>? <vmip3s0>? <cs> <Acuse>}\n",
    "           \"\"\"\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
